{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<font size=5>\n",
    "<font/>\n",
    "<p></p>\n",
    " <br/>\n",
    "\n",
    "<font color=#FF7500>\n",
    "Sharif University of Technology - Departmenet of Computer Engineering\n",
    "</font>\n",
    "<p></p>\n",
    "<font color=blue>\n",
    "Linear Algebra\n",
    "</font>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Spring 2023\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr/>\n",
    "\t\t<div align=center>\n",
    "\t\t    <font color=red size=6>\n",
    "\t\t\t    <br />\n",
    "Practical Assignment 1\n",
    "            \t<br/>\n",
    "\t\t\t</font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=\"orange\" size=6>\n",
    "    Q1\n",
    "    </font>\n",
    "    <hr/>\n",
    "</div>\n",
    "As you know, computers are quite \"dumb\" and constantly strive to be as unintelligent as possible. One example of their \"dumbness\" is their inability to understand texts and the similarities between them. Thus, in order to help computers understand a text, we have no choice but to produce a vector representation of it. A well-known vector representation of text in computers is the ASCII or UTF code, which is used to store characters and to store a text using a sequence of them. However, the problem with this representation is that it has no connection to the semantic dimension of words and sentences.\n",
    "\n",
    "We aim to introduce a new representation for sentences. Suppose we have a collection of m sentences, which together consist of n distinct words. Now, using these words and sentences, we wish to define the following two matrices:\n",
    "\n",
    "**(a) Word Frequency Matrix:** The more frequently a word appears in a sentence, the more likely it is to play a significant role in the meaning of that sentence. The word frequency matrix, which we denote by F, is an n × m matrix where the element in row i and column j is equal to the frequency of word j in sentence i. For example, in the sentence:\n",
    "\n",
    "\"I like eating dessert in the desert,\"\n",
    "\n",
    "we have 6 words, and the word \"desert\" appears twice. Therefore, the frequency of this word in the sentence is 2.\n",
    "\n",
    "**(b) Word Commonality Matrix:** The more frequently a word appears across many sentences, the less semantic weight it is likely to carry. For instance, prepositions and conjunctions appear in the vast majority of sentences. The word commonality matrix (or vector) is an n × 1 matrix where the element in row i is the logarithm of the ratio of the total number of sentences to the number of sentences that contain word i. Formally, if D is the set of all sentences and $D_i$ is the subset of sentences that contain word i, the element in row i of the word commonality matrix, which we denote by I, is given by:\n",
    "$$I[i] = ln \\frac{|D|}{|D_i|}\n",
    "$$\n",
    "Now, the representation of sentence i is considered to be the element-wise product of row i of the frequency matrix and the word commonality vector.\n",
    "\n",
    "In this problem, we are given a set called S, which contains several sentences. The first step is to compute the representations of these sentences. Then, we are given a sentence query for which its representation must be computed in the same way as for the sentences above. Finally, we need to return the index of the sentence in S that is most similar to the query. This similarity is determined by calculating the angle between their representations.\n",
    "\n",
    "Before performing any of these steps, punctuation must be removed from the text, and letter case should be ignored (i.e., treat upper and lower case letters as the same).\n",
    "\n",
    "**Input:** The first line of the input contains an integer n, which represents the size of the set |S|. In the next n lines, each line contains a sentence from the set S. Finally, the last line contains the query sentence.\n",
    "\n",
    "**Output:** The output should be the index of the sentence that has the highest similarity to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    return sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_frequencies(sentences):\n",
    "    word_list = set()\n",
    "    word_frequencies = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words = preprocess(sentence)\n",
    "        word_count = Counter(words)\n",
    "        word_list.update(words)\n",
    "        word_frequencies.append(word_count)\n",
    "    \n",
    "    return list(word_list), word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrices(word_list, word_frequencies, sentences):\n",
    "    n = len(word_list)\n",
    "    m = len(sentences)\n",
    "    word_index = {word: i for i, word in enumerate(word_list)}\n",
    "    \n",
    "    F = np.zeros((m, n))\n",
    "    I = np.zeros(n)\n",
    "    \n",
    "    for j, word in enumerate(word_list):\n",
    "        word_count_in_sentences = sum(1 for freq in word_frequencies if word in freq)\n",
    "        I[j] = math.log(m / word_count_in_sentences) if word_count_in_sentences > 0 else 0\n",
    "    \n",
    "    for i, freq in enumerate(word_frequencies):\n",
    "        for word, count in freq.items():\n",
    "            F[i, word_index[word]] = count\n",
    "            \n",
    "    return F, I\n",
    "\n",
    "def sentence_representation(F, I):\n",
    "    return F * I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude_v1 = np.linalg.norm(v1)\n",
    "    magnitude_v2 = np.linalg.norm(v2)\n",
    "    if magnitude_v1 == 0 or magnitude_v2 == 0:\n",
    "        return 0\n",
    "    return dot_product / (magnitude_v1 * magnitude_v2)\n",
    "\n",
    "def find_most_similar_sentence(S):\n",
    "    sentences = S[:-1]\n",
    "    query_sentence = S[-1]\n",
    "    word_list, word_frequencies = compute_word_frequencies(sentences)\n",
    "    query_frequency = Counter(preprocess(query_sentence))\n",
    "    F, I = build_matrices(word_list, word_frequencies, sentences)\n",
    "    sentence_vectors = sentence_representation(F, I)\n",
    "    query_vector = np.zeros(len(word_list))\n",
    "    word_index = {word: i for i, word in enumerate(word_list)}\n",
    "    \n",
    "    for word, count in query_frequency.items():\n",
    "        if word in word_index:\n",
    "            idx = word_index[word]\n",
    "            query_vector[idx] = count * I[idx]\n",
    "    \n",
    "    similarities = [cosine_similarity(sentence_vectors[i], query_vector) for i in range(len(sentences))]\n",
    "    \n",
    "    return np.argmax(similarities) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(test_input):\n",
    "    test_case = test_input.strip().split('\\n')\n",
    "    n = int(test_case[0])\n",
    "    S = test_case[1:]\n",
    "    most_similar_sentence_index = find_most_similar_sentence(S)\n",
    "    print(most_similar_sentence_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "test_input = '''\n",
    "3\n",
    "I like eating dessert in the desert\n",
    "The sky is clear today\n",
    "I will go to the desert tomorrow\n",
    "desert in summer is hot\n",
    "'''\n",
    "similarity(test_input) # The output should be 1\n",
    "\n",
    "\n",
    "test_input = '''\n",
    "10\n",
    "evening? majority? relinquish harmful, jump. nap score. monstrous? jump. disposition? bulb greet bulb? displace \n",
    "jump jacket. suite. motivation cultural. the. care? council? flag? \n",
    "mosquito, tiptoe. job issue. provision leaflet. particle job, identity. horn, architecture evening creation \n",
    "vegetable, stadium, bury? chase? chase. disposition. \n",
    "gallery range? layout, able? cane, earthflax. delicate? productive, \n",
    "gutter. night. representative, impound. qualification, \n",
    "confusion, displace sunshine? put. choke. feature, relinquish cultural dominate. attraction? superior, determine? bounce? tiger, \n",
    "gallery, argument magnitude, score layout. confine? impound? diamond, qualification is? identity \n",
    "snail, preach, simplicity paragraph. marsh, circulation, gutter, anniversary, attraction, evening? is \n",
    "issue. circumstance? able jump. eyebrow, \n",
    "evening. volcano? category. trivial. fuel morale. \n",
    "'''\n",
    "similarity(test_input) # The output should be 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
