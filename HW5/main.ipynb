{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<font size=5>\n",
    "<font/>\n",
    "<p></p>\n",
    " <br/>\n",
    "\n",
    "<font color=#FF7500>\n",
    "Sharif University of Technology - Departmenet of Computer Engineering\n",
    "</font>\n",
    "<p></p>\n",
    "<font color=blue>\n",
    "Linear Algebra\n",
    "</font>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Spring 2023\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr/>\n",
    "\t\t<div align=center>\n",
    "\t\t    <font color=red size=6>\n",
    "\t\t\t    <br />\n",
    "Practical Assignment 5\n",
    "            \t<br/>\n",
    "\t\t\t</font>\n",
    "</font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=\"orange\" size=6>\n",
    "    Q1\n",
    "    </font>\n",
    "    <hr/>\n",
    "</div>\n",
    "In machine learning applications, one of the most important steps is learning an appropriate representation for the data. In many cases, the data is in a form that is not easily analyzable by machines. For instance, working with textual data is very difficult for machines. In other cases, the data may be numeric, but the size might be too large to be analyzed effectively. For example, an adjacency matrix of a graph contains numerical data, but analyzing it in its large size may not provide a suitable representation for each vertex or the entire graph.\n",
    "\n",
    "One of the conventional methods used in machine learning for learning representations is matrix decomposition. For this purpose, various methods are employed, such as Non-negative Matrix Factorization (NMF) or Singular Value Decomposition (SVD). In this question, we will use SVD to learn a suitable representation and apply it to solve a simple problem.\n",
    "\n",
    "Suppose we have n data points, each with m features. We can represent these data points as an n × m matrix, where each row corresponds to a data point and each column corresponds to a feature. Assume this matrix has d singular values. Therefore, the SVD of this matrix can be written as: \n",
    "$$A = UΣV^T$$\n",
    "where:\n",
    "- U is a m × d matrix,\n",
    "- Σ is a d × d diagonal matrix of singular values, and\n",
    "- V is a n × d matrix.\n",
    "\n",
    "The matrix U gives a representation of the data points with dimension d. If the singular values are ordered in descending order along the diagonal of Σ, we can reduce the dimensionality by selecting only the largest d' singular values. Therefore, we can also perform dimensionality reduction while learning the representation.\n",
    "\n",
    "In this problem, we will use this representation learning method to analyze textual data. Consider a term-document matrix, where each entry represents the frequency of a term (word) in a document. By using SVD, we can find a suitable representation for each sentence. We can then use cosine similarity to find the similarity between any pair of sentences.\n",
    "\n",
    "**Input:** The first line of the input contains three integers a, b, and d, representing the number of documents in the dataset, the number of queries, and the dimension of the learned representation, respectively.\n",
    "In the next a + b lines, the sentences representing the documents and queries are provided.\n",
    "\n",
    "**Output:** For each query, print the index of the document that is most similar to the i-th query based on cosine similarity. The indexing starts from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_inputs(test_input):\n",
    "    test_case = test_input.split(\"\\n\")\n",
    "    digits = test_case[0].split(\" \")\n",
    "    a = int(digits[0])\n",
    "    b = int(digits[1])\n",
    "    d = int(digits[2])\n",
    "    \n",
    "    test_case = test_case[1:]\n",
    "\n",
    "    documents = []\n",
    "    questions = []\n",
    "    for i in range(a):\n",
    "        documents.append(test_case[i])\n",
    "    \n",
    "    test_case = test_case[a:]\n",
    "    \n",
    "    stop_words = {\"one\", \"is\", \"a\", \"by\", \"in\", \"an\", \"the\", \"to\", \"with\"}\n",
    "    for i in range(b):\n",
    "        sentence = test_case[i].rstrip()\n",
    "        filtered_sentence = ' '.join(\n",
    "        word for word in sentence.split() if word not in stop_words)\n",
    "        questions.append(filtered_sentence)\n",
    "\n",
    "    return a, b, d, documents, questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_similarity(a, b, d, documents, questions):\n",
    "    for i in range(b):\n",
    "        q = questions[i].split()\n",
    "        ones_mat = np.ones(shape=(len(q), 1))\n",
    "        zeros_mat = np.zeros(shape=(len(q), a + 1))\n",
    "        for j in range(len(q)):\n",
    "            zeros_mat[j][0] = ones_mat[j][0]\n",
    "            for k in range(1, a + 1):\n",
    "                zeros_mat[j][k] = documents[k - 1].count(q[j])\n",
    "        u, sigma, v_t = np.linalg.svd(zeros_mat)\n",
    "        sigma = np.diag(sigma)\n",
    "        v_t = v_t.T\n",
    "        U = u[:, :d]\n",
    "        SIGMA = sigma[:d, :d]\n",
    "        V = v_t[:, :d]\n",
    "        max_similar = 0\n",
    "        max_similar_col = 2\n",
    "        for k in range(1, a + 1):\n",
    "            tmp = int(round(pow(10, 18) * (V[:, 0] @ V[:, k]) / (np.linalg.norm(V[:, 0]) * np.linalg.norm(u)), 4))\n",
    "            if tmp > max_similar:\n",
    "                max_similar_col = k\n",
    "                max_similar = tmp\n",
    "        print(max_similar_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(test_case):\n",
    "    a, b, d, documents, questions = get_inputs(test_case)\n",
    "    max_similarity(a, b, d, documents, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "test_case = '''4 2 6\n",
    "I love aircrafts\n",
    "Airbus A380 is one of the safest aircraft ever in the world\n",
    "Boeing 777 is named as triple 7 in the UK aviation\n",
    "F22 Raptor is the most adavenced air superiority fighter ever made by the united states\n",
    "Where do you like to travel with a Boeing aircraft\n",
    "what is the safest aircraft in the world'''\n",
    "\n",
    "find(test_case)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
